{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classifier\n",
    "\n",
    "This Notebook uses a neural network that inputs an image of a handwritten digit, and predicts what digit it is (0 to 10)\n",
    "\n",
    "I am making this classifier while learning the basics of DL and neural networks online, from Micheal Nelson's online book, the link of which is available in the README file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Network` class\n",
    "\n",
    "The following class represents  a basic neural network, with attributes like number of layers, number of neurons in each layer (**size**), bias, and weights.\n",
    "\n",
    "You can create a neural network by creating an instance of the following class:\n",
    "\n",
    "```\n",
    "    myNetwork = Network(size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        Constructor to initalize the object attributes\n",
    "        Assumption: layer 0 is the input layer (so it won't have any biases)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.size = size # number of neurons in each layer\n",
    "        self.num_layers = len(size) # number of layers\n",
    "        self.bias = [np.random.randn(1, l) for l in size[1:]] # randomly initalize bias of each layer from layer 1\n",
    "        self.weight = [np.random.randn(l, m) for m, l in zip(size[:-1], size[1:])] # randomly initiliaze biases in the same way\n",
    "    \n",
    "    def sigmoid(z):\n",
    "        \"\"\"return sigma(z)\"\"\"\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        \"\"\" \n",
    "        Compute sigma(w.x + b), where w is list of weights for each layer, and b is the list of biases for each layer.\n",
    "        Return the feedforward output after going through all layers\n",
    "        \"\"\"\n",
    "        for w,b in zip(self.weight, self.bias):\n",
    "            y = sigmoid(np.dot(w,x) + b)\n",
    "        return y\n",
    "    \n",
    "    def printElements(self):\n",
    "        \"\"\" Print the elements of the current instance of the neural network \"\"\"\n",
    "        \n",
    "        print(f'This neural network has: \\n{self.num_layers} number of layers, \\n{self.size} neurons in each layer, \\n{self.bias} as biases for each layer, and \\n{self.weight} as weights for each layer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 10 18]\n",
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.43095333,  1.92086685, -1.00471544]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment the following lines to understand how a zip works\n",
    "l1 = [1,2,3]\n",
    "l2 = [4,5,6]\n",
    "# print(f'first zip: {list(zip(l1,l2))}')\n",
    "# for i in zip(l1,l2):\n",
    "#     print(i)\n",
    "\n",
    "# l = [1,2,3,4,5]\n",
    "# print(f'second zip: {list(zip(l, l[1:]))}')\n",
    "print(np.multiply(l1,l2))\n",
    "print(list(zip(l1,l2)))\n",
    "\n",
    "np.random.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This neural network has: \n",
      "3 number of layers, \n",
      "[2, 3, 1] neurons in each layer, \n",
      "[array([[ 0.42276532,  0.62805736, -0.90569098]]), array([[ 0.87342857]])] as biases for each layer, and \n",
      "[array([[ 0.09692779, -1.97659621],\n",
      "       [-1.32880751, -1.3783241 ],\n",
      "       [ 1.07809407,  0.32457011]]), array([[ 0.85236205,  0.6843358 ,  0.1941862 ]])] as weights for each layer.\n"
     ]
    }
   ],
   "source": [
    "myNet = Network([2,3,1])\n",
    "myNet.printElements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
